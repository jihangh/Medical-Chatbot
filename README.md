# ğŸ©º Medical Chatbot with RAG

A **Retrieval-Augmented Generation (RAG)** chatbot for general medical question answering, powered by **OpenAI GPT-5 nano** and built with **LangChain**. The system uses a **hybrid retrieval pipeline** to search trusted medical knowledge from *The Gale Encyclopedia of Medicine* and generate concise, contextual, and user-friendly answers.

This project demonstrates how to combine modern LLMs with vector databases and sparse retrieval to build production-style medical QA systems.

---

## âš ï¸ Medical Disclaimer

> **IMPORTANT:** This chatbot is designed for **informational and educational purposes only**. It is **NOT** a substitute for professional medical advice, diagnosis, or treatment.

âœ… This tool should be used as a **supplement**, not a replacement, for professional medical consultation.

---

## âœ¨ Key Features

* **ğŸš€ Fast & Cost-Effective LLM**
  Powered by **OpenAI GPT-5 nano** for concise, efficient responses.

* **ğŸ§  Hybrid Retrieval (Dense + Sparse)**
  Combines semantic embeddings with keyword-based search for higher accuracy using a tunable `alpha` score.

* **ğŸ“š Trusted Medical Knowledge Base**
  Built from *The Gale Encyclopedia of Medicine*.

* **ğŸ§© Smart Chunking**
  Uses LangChainâ€™s `RecursiveCharacterTextSplitter` with medical-aware chunking strategy.

* **ğŸ” Vector Search with Pinecone**
  Stores and retrieves medical documents efficiently at scale.

* **ğŸ–¥ï¸ Interactive UI**
  Simple and clean **Gradio** interface for real-time medical Q&A.

* **ğŸ”— LangChain Orchestration**
  Seamlessly integrates LLMs, retrievers, embeddings, and memory.

* **ğŸ—‚ï¸ Session-Based Conversational Memory**
  Maintains conversation context per user session using `langgraph.checkpoint.memory.InMemorySaver`, with the Gradio `session_id` passed as the LangGraph `thread_id` to ensure stable, multi-turn interactions.

---

## ğŸ—ï¸ Architecture Overview

```
User Query
   â†“
Gradio Interface
   â†“
LangChain Orchestrator
   â†“
Hybrid Retriever (Dense + Sparse)
   â†“
Pinecone Vector Database
   â†“
Context Assembly
   â†“
OpenAI GPT-5 nano
   â†“
Answer to User
```

---

## ğŸ”§ Tech Stack

* **LLM:** OpenAI GPT-5 nano
* **Framework:** LangChain
* **Vector DB:** Pinecone
* **Embeddings:**

  * `text-embedding-3-large` (dense)
  * `pinecone-sparse-english-v0` (sparse)
* **Interface:** Gradio
* **Language:** Python

---

## ğŸ® Demo

You can interact with the chatbot via the **Gradio interface** for real-time medical Q&A.

Example queries:

* "What are the symptoms of diabetes?"
* "How is hypertension treated?"
* "What causes migraine headaches?"
* "Explain the difference between Type 1 and Type 2 diabetes."

---

## âœ… Prerequisites

* Python **3.10+** (tested on **3.12.9**)
* OpenAI API key
* Pinecone API key

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/medical-qa-chatbot.git
cd Medical-Chatbot
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate.bat
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Set Up Environment Variables

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
```

---

### 5ï¸âƒ£ Configure the System

Edit `config.yaml`:

```yaml
index_name: your_index_name
name_space: your_namespace
```

Feel free to adjust other parameters such as chunk size, retriever alpha, and model settings.

---

### 6ï¸âƒ£ Customize the System Prompt

You can modify the behavior of the assistant in:

```
system_prompt.txt
```

This controls tone, safety, and answer formatting.

---

## ğŸ’» Usage

Start the chatbot:

```bash
python gradioapp.py
```

The Gradio interface will launch at:

```
http://localhost:7860
```

---

## âš ï¸ Limitations & Considerations

### ğŸ”§ Technical

* Answers are limited to content in *The Gale Encyclopedia of Medicine*.
* May not reflect the most recent clinical guidelines.
* Performance depends on query clarity and retrieved context quality.

### âš–ï¸ Ethical

* Not suitable for emergency medical situations.
* Should not be used for self-diagnosis or treatment decisions.
* Possible biases from source material.
* Human medical professional oversight is essential.
---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome. Feel free to fork the project and submit a PR.

---

## â­ Acknowledgments

* OpenAI
* LangChain
* Pinecone
* The Gale Encyclopedia of Medicine

---

Happy building! ğŸš€
